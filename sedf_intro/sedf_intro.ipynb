{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87369ff5",
   "metadata": {},
   "source": [
    "# Introduction to the Spatially Enabled DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9665bf7",
   "metadata": {},
   "source": [
    "This notebook will introduce Esri's Spatially Enabled DataFrame structure, which is part of the ArcGIS API for Python. It's an extremely handy tool in certain situations, as it extends the Pandas DataFrame structure to add spatial capabilities. The GeoPandas package provides similar functionality, but it introduces varying levels of frustration depending on the environment you're trying to use it in. The ArcGIS API for Python (along with Pandas and ArcPy) is already conveniently installed in the default ArcGIS Pro Python environment. The Spatially Enabled DataFrame gives us access to some powerful data cleaning and analysis tools. Further, it integrates well with Jupyter Notebooks and gives us some decent visualization options completely outside the confines of ArcGIS Pro.\n",
    "\n",
    "*Note: For simplicity, this tutorial assumes you have access to the default ArcGIS Pro Python environment. This environment includes the ArcGIS API for Python, ArcPy, and Pandas, all of which we'll make use of. You can, however, use the Spatially Enabled DataFrame with a standard Python installation.  Installation instructions are at: https://developers.arcgis.com/python/guide/install-and-set-up/. You'll also need to install Pandas. Unlike most Esri products, the API for Python is freely available and doesn't require any sort of license. They assume you'll be using this with an ArcGIS Enterprise setup or ArcGIS Online, and they enforce this by requiring either access to ArcPy or authentication to ArcGIS Online or ArcGIS Enterprise. Read/write from/to feature classes is usually done with ArcPy, but it can be done with the pyshp package (shapely and fiona are also required) as long as you are able to authenticate somehow. This makes it possible to run in an environment without access to the typical ArcGIS Python installation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a14a83",
   "metadata": {},
   "source": [
    "## 1 Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed60f9f8",
   "metadata": {},
   "source": [
    "We'll use the os module to deal with some file path stuff. The data_path variable should be set to wherever you've stored the data folder associated with this tutorial. If it's in the same folder as the tutorial notebook file, you shouldn't need to change anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6b7090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = \"Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4eef85",
   "metadata": {},
   "source": [
    "The foundation of most scripts that make use of the API is the `GIS` object from the `arcgis.gis` module. *(`import arcgis` would get us access to the whole API for Python, but that's not particularly useful for what we're doing here.)* This object represents a connection to a GIS portal. Using the `GIS()` constructor without passing any parameters into it creates an anonymous login to ArcGIS Online and restricts us to publicly available or local datasets (as long as we've got access to ArcPy as well). We'll need this for data visualization inside the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "\n",
    "mygis = GIS()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9acc80",
   "metadata": {},
   "source": [
    "We need to provide some authentication if we want to access resources from a specific data portal. We won't do that here, but plenty of examples can be found in the ArcGIS API for Python documentation: https://developers.arcgis.com/python/\n",
    "\n",
    "Let's use our `GIS` object to show a simple basemap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f65f615",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymap = mygis.map(\"USA\", zoomlevel=2)\n",
    "\n",
    "mymap.basemap = \"streets-vector\"\n",
    "\n",
    "mymap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e1f703",
   "metadata": {},
   "source": [
    "Ok, that's enough setup. Let's move on to..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b1c7e",
   "metadata": {},
   "source": [
    "## 2 Reading and Visualizing Local Geospatial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce684c2c",
   "metadata": {},
   "source": [
    "A Spatially Enabled DataFrame adds the `spatial` namespace to the Pandas DataFrame to give it spatial capabilities. The Pandas DataFrame is a great way to handle tabular data using Python, and adding sptial capabilities means that it can make use of any geometries that might be associated with that tabular data. The Spatially Enabled DataFrame allows us to read and write spatial data formats, visualize spatial data, and perform geospatial operations on the data.\n",
    "\n",
    "*Another Note: Until recently, very similar functionality was available through something called Spatial DataFrames. These are still available for use but are not actively developed and have been effectively replaced by Spatially Enabled DataFrames.*\n",
    "\n",
    "Let's see what methods and attributes are available in the `spatial` namespace. We'll need to import the Pandas package to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8b50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "\n",
    "dir(pd.DataFrame.spatial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d74ddd",
   "metadata": {},
   "source": [
    "Well, that's a lot of spatial-sounding stuff. Of particular interest, we see can a handful of methods that start with \"from_\". These allow us to import local data into the Spatially Enabled DataFrame format *(from here on out this will be referred to as SEDF because I don't want to type the full name any more)*. Let's import some data and see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54016593",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqpath = os.path.join(data_path, \"earthquakes.shp\")\n",
    "\n",
    "sedf = pd.DataFrame.spatial.from_featureclass(eqpath)\n",
    "\n",
    "sedf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd31e9c3",
   "metadata": {},
   "source": [
    "Let's take a look at the column info for this SEDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc144a0",
   "metadata": {},
   "source": [
    "We can see that we've got a geometry column, which is what makes the SEDF special (and spatial). We can also get spatial reference information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.spatial.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d284e",
   "metadata": {},
   "source": [
    "Now that we've got a Spatially Enabled DataFrame set up, we can go ahead and map it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0311601",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.spatial.plot(mymap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57192cb",
   "metadata": {},
   "source": [
    "You may have realized that the layer was added to the map cell up above. We specified that we wanted it to show up in the \"mymap\" map widget, so it did just that. If we want to add data to a new map, we need to create a new map.\n",
    "\n",
    "You have also noted that it looked like trash. We can do a few things to fix this. The `plot` method has quite a few optional parameters for specifying how we want our map to look. It uses a mix of esri and matplotlib syntax and the documentation leaves a bit to be desired, but it generally works: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756ad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqmap = mygis.map(\"USA\", zoomlevel=3)\n",
    "\n",
    "sedf.spatial.plot(map_widget=eqmap,\n",
    "                  renderer_type='c',\n",
    "                  method='esriClassifyNaturalBreaks',\n",
    "                  class_count= 10,\n",
    "                  col='Magnitude',\n",
    "                  marker_size=8,\n",
    "                  line_width=0.5,\n",
    "                  cmap='Reds')\n",
    "\n",
    "eqmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1861952e",
   "metadata": {},
   "source": [
    "That's a bit better. Not great, but we're not here to learn cartography. Let's move on to some slightly more interesting things.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f8bf6d",
   "metadata": {},
   "source": [
    "## 3 Data Cleaning and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b78ed",
   "metadata": {},
   "source": [
    "Spatial data visualization inside of a notebook is pretty neat, but it wouldn't be worth much if we couldn't work with the data in a meaningful way. Fortunately, a SEDF is a Pandas DataFrame at its core, so we can do all kinds of useful stuff. The earthquake data above is a bit messy, so let's start by cleaning it up a bit. The index and the FID are columns are duplicates, so let's make the FID column the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.set_index([\"FID\"], inplace=True)\n",
    "\n",
    "sedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce8704",
   "metadata": {},
   "source": [
    "We also can't see all the columns in the DataFrame, so let's change that. The code below sets a global option for Pandas, so it will work for all DataFrames displayed from here on out. If you've got a huge number of columns, you might want to be more careful with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d64bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "sedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e6ee7e",
   "metadata": {},
   "source": [
    "Now we can see all the garbage columns that we might want to delete. Let's get rid of everything we don't want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162240f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.drop(columns=[\"Depth_Erro\", \n",
    "                   \"Depth_Seis\", \n",
    "                   \"Magnitude_\", \n",
    "                   \"Magnitude1\",\n",
    "                   \"Magnitud_1\",\n",
    "                   \"Azimuthal_\",\n",
    "                   \"Horizontal\",\n",
    "                   \"Horizont_1\",\n",
    "                   \"Root_Mean_\",\n",
    "                   \"Location_S\",\n",
    "                   \"Magnitud_2\"], inplace=True)\n",
    "\n",
    "sedf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecbbac5",
   "metadata": {},
   "source": [
    "Ok, that looks much nicer. Let's explore the data a bit. Since this is Pandas under the hood, indexing works just like it does for a regular DataFrame. Here's a single feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb508f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf[sedf[\"ID\"]==\"UW10530748\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1a319c",
   "metadata": {},
   "source": [
    "Here's a set of features that match a condition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf[sedf[\"Magnitude\"]>=8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77824ee2",
   "metadata": {},
   "source": [
    "Want to know the maximum magnitude value? We can get that as just the number or the whole associated feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d964d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxval = sedf[\"Magnitude\"].max()\n",
    "\n",
    "maxrow= sedf.loc[sedf[\"Magnitude\"].idxmax()]\n",
    "\n",
    "print(maxval)\n",
    "print(\"---------------\")\n",
    "print(maxrow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f71caa",
   "metadata": {},
   "source": [
    "What about plotting? Well, we can use matplotlib for more complex stuff, but a simple histogram can be done without any trouble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df7dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.hist(column=\"Magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f65f5",
   "metadata": {},
   "source": [
    "Same with scatter plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf.plot.scatter(x=\"Depth\", y=\"Magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7705b43",
   "metadata": {},
   "source": [
    "We can get all the unique values in a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363670b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sedf[\"Type\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fed7b0",
   "metadata": {},
   "source": [
    "Let's check out what's going on with nuclear explosions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b7097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nukes = sedf[(sedf[\"Type\"]==\"Nuclear Explosion\") & (sedf[\"Date\"]>='11/09/1989')]\n",
    "\n",
    "nukes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf9c34",
   "metadata": {},
   "source": [
    "Looks like there are some similar lats and longs. Let's see who's doing all this testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cc0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nukemap = mygis.map(zoomlevel=1)\n",
    "\n",
    "nukemap.basemap = \"national-geographic\"\n",
    "\n",
    "nukes.spatial.plot(map_widget=nukemap,\n",
    "                  renderer_type='s',\n",
    "                  marker_size=10,\n",
    "                  line_width=0.5,\n",
    "                  cmap='Reds',\n",
    "                  cstop=50)\n",
    "\n",
    "nukemap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93c88f",
   "metadata": {},
   "source": [
    "## 4 Intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2b08f",
   "metadata": {},
   "source": [
    "Let's do some slightly more complex analysis. What if we want a list of all the earthquakes within 100 miles of Japan? We'll start by importing a shapefile of national boundaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609a385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_path = os.path.join(data_path, \"World_Countries_Generalized.shp\")\n",
    "\n",
    "countries = pd.DataFrame.spatial.from_featureclass(country_path)\n",
    "\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becba0b3",
   "metadata": {},
   "source": [
    "Let's pull out Japan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6592095",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries[countries[\"COUNTRY\"]==\"Japan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91dd14a",
   "metadata": {},
   "source": [
    "We can take a look at that feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.SHAPE[113]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0736f644",
   "metadata": {},
   "source": [
    "Yep, that's Japan. Let's do a little buffer trial run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.SHAPE[113].buffer(distance=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687630f5",
   "metadata": {},
   "source": [
    "Hmm. That's not what we want. We should at least be able see the general shape of the country. Let's see what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.spatial.sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f600cf",
   "metadata": {},
   "source": [
    "Ah, we're in WGS84 and the units are in degrees. The meaning of 100 units in this case is probably ambiguous and definitely not what we want. Let's try bringing it in with a different projection. We'll use UTM 54N (WKID 32654). Probably not perfect, but at least it's close and in meters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b9715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.geometry import SpatialReference\n",
    "\n",
    "countries_proj = pd.DataFrame.spatial.from_featureclass(country_path, sr=SpatialReference(32654).as_arcpy)\n",
    "\n",
    "countries_proj[countries_proj[\"COUNTRY\"]==\"Japan\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e0117",
   "metadata": {},
   "source": [
    "And the buffer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3efc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_proj.SHAPE[113].buffer(distance=160934)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34013745",
   "metadata": {},
   "source": [
    "Much better! Ok, let's make a SDEF that contains only this buffered feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4173f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "japan = countries_proj[countries_proj[\"COUNTRY\"]==\"Japan\"].copy()\n",
    "\n",
    "japan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8356da45",
   "metadata": {},
   "source": [
    "Now for the buffer. We'll do this by replacing the existing geometry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "japan[\"SHAPE\"] = japan.SHAPE.geom.buffer(distance=160934)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21de4c9f",
   "metadata": {},
   "source": [
    "Checking the shape..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "japan.SHAPE[113]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a2347",
   "metadata": {},
   "source": [
    "The last step is to create a sort of query that gets everything that's not outside of our area of interest and apply that query to our earthquake SEDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "japan_query = sedf.SHAPE.geom.disjoint(japan.SHAPE[113]) == False\n",
    "\n",
    "japan_quakes = quakes_proj[japan_query]\n",
    "\n",
    "japan_quakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e00c4",
   "metadata": {},
   "source": [
    "Mapping the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f35c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "japanmap = mygis.map(\"Japan\", zoomlevel=4)\n",
    "\n",
    "japan.spatial.plot(map_widget=japanmap)\n",
    "\n",
    "japan_quakes.spatial.plot(map_widget=japanmap,\n",
    "                  renderer_type='c',\n",
    "                  method='esriClassifyNaturalBreaks',\n",
    "                  class_count= 10,\n",
    "                  col='Magnitude',\n",
    "                  marker_size=8,\n",
    "                  line_width=0.5,\n",
    "                  cmap='Reds')\n",
    "\n",
    "japanmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260b1a1",
   "metadata": {},
   "source": [
    "## 5 Writing SEDF to Feature Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e11fb",
   "metadata": {},
   "source": [
    "Now that we've done all this data manipulation, let's save our results back out to a Shapefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f8257",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.join(data_path, \"japan_quakes.shp\")\n",
    "\n",
    "japan_quakes.spatial.to_featureclass(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e370c42",
   "metadata": {},
   "source": [
    "##  6 More Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d26daf",
   "metadata": {},
   "source": [
    "This is only a small portion of what can be done with SEDFs and the ArcGIS API for Python. If you want to learn more, the Esri developer documentation (https://developers.arcgis.com/python/) is a good place to start. Even better, they have a GitHub repo with tons of examples (https://github.com/Esri/arcgis-python-api/tree/master). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
